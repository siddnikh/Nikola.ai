{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Nikolatransformer_chatbot_tf2_fix.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nd8ddC7NQ8uZ"
      },
      "source": [
        "# Demo Transformer Chatbot as proof of concept for the bigger NMT Chatbot : Nikola.ai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rHMPkA2eQrpT"
      },
      "source": [
        "In this Jupyter Notebook, we demonstrate a smaller version of Nikola.ai. Nikola.ai is planned to be a Neural Machine Translator chatbot trained on about 40GB of data from Reddit. The code for the Neural Machine chatbot is prepared. However, due to constraints like lack of computational power and low bandwidth, we have prepared a proof of concept using Transformers.\n",
        "\n",
        "Transformer, proposed in the paper Attention is All You Need, is a neural network architecture solely based on self-attention mechanism and is very parallelizable.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mb_5bl7G_n30",
        "outputId": "3013d081-2a64-460e-9a4a-7d21f02f3df4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        }
      },
      "source": [
        "from __future__ import print_function, unicode_literals, division, absolute_import\n",
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(1234)\n",
        "!pip install tensorflow-datasets==1.2.0\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "import tensorflow_datasets as tflowdatasets\n",
        "import matplotlib.pyplot as plot\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "Collecting tensorflow-datasets==1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/34/ff424223ed4331006aaa929efc8360b6459d427063dc59fc7b75d7e4bab3/tensorflow_datasets-1.2.0-py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py in /tensorflow-2.1.0/python3.6 (from tensorflow-datasets==1.2.0) (0.9.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (0.15.2)\n",
            "Requirement already satisfied: numpy in /tensorflow-2.1.0/python3.6 (from tensorflow-datasets==1.2.0) (1.18.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (0.3.1.1)\n",
            "Requirement already satisfied: six in /tensorflow-2.1.0/python3.6 (from tensorflow-datasets==1.2.0) (1.14.0)\n",
            "Requirement already satisfied: wrapt in /tensorflow-2.1.0/python3.6 (from tensorflow-datasets==1.2.0) (1.11.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /tensorflow-2.1.0/python3.6 (from tensorflow-datasets==1.2.0) (3.11.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (19.3.0)\n",
            "Requirement already satisfied: termcolor in /tensorflow-2.1.0/python3.6 (from tensorflow-datasets==1.2.0) (1.1.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (2.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /tensorflow-2.1.0/python3.6 (from tensorflow-datasets==1.2.0) (2.22.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (4.28.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (5.4.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (0.16.0)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets==1.2.0) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /tensorflow-2.1.0/python3.6 (from protobuf>=3.6.1->tensorflow-datasets==1.2.0) (45.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.1.0/python3.6 (from requests>=2.19.0->tensorflow-datasets==1.2.0) (2019.11.28)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.1.0/python3.6 (from requests>=2.19.0->tensorflow-datasets==1.2.0) (1.25.7)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /tensorflow-2.1.0/python3.6 (from requests>=2.19.0->tensorflow-datasets==1.2.0) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /tensorflow-2.1.0/python3.6 (from requests>=2.19.0->tensorflow-datasets==1.2.0) (3.0.4)\n",
            "Installing collected packages: tensorflow-datasets\n",
            "  Found existing installation: tensorflow-datasets 1.3.2\n",
            "    Uninstalling tensorflow-datasets-1.3.2:\n",
            "      Successfully uninstalled tensorflow-datasets-1.3.2\n",
            "Successfully installed tensorflow-datasets-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y0AqALdZCbCW"
      },
      "source": [
        "##Prepare Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "awb4RH3XCobf"
      },
      "source": [
        "Dataset : [Cornell Movie-Dialogs Corpus](https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html), which contains more than 220 thousands conversational exchanges between more than 10k pairs of movie characters, as our dataset.\n",
        "\n",
        "`movie_conversations.txt` contains list of the conversation IDs and `movie_lines.text` contains the text of assoicated with each conversation ID. For further  information regarding the dataset, please check the README file in the zip file.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S17Nfn6W_vhd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "49b3d08e-5927-457c-b399-af4394ff033f"
      },
      "source": [
        "ptz = tf.keras.utils.get_file(\n",
        "    'cornell_movie_dialogs.zip',\n",
        "    origin=\n",
        "    'http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip',\n",
        "    extract=True)\n",
        "\n",
        "ptd = os.path.join(\n",
        "    os.path.dirname(ptz), \"cornell movie-dialogs corpus\")\n",
        "\n",
        "ptml = os.path.join(ptd, 'movie_lines.txt')\n",
        "ptmc = os.path.join(ptd,'movie_conversations.txt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
            "9920512/9916637 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iZMuzj0cVr3E"
      },
      "source": [
        "### Load and preprocess data\n",
        "\n",
        "`MAX_SAMPLES=25000` \n",
        "`MAX_LENGTH=40`.\n",
        "\n",
        "  Steps :\n",
        "* Extract `MAX_SAMPLES` conversation pairs into list of `questions` and `answers.\n",
        "* Preprocess each sentence by removing special characters in each sentence.\n",
        "* Build tokenizer (map text to ID and ID to text) using [TensorFlow Datasets SubwordTextEncoder](https://www.tensorflow.org/datasets/api_docs/python/tfds/features/text/SubwordTextEncoder).\n",
        "* Tokenize each sentence and add `START_TOKEN` and `END_TOKEN` to indicate the start and end of each sentence.\n",
        "* Filter out sentence that has more than `MAX_LENGTH` tokens.\n",
        "* Pad tokenized sentences to `MAX_LENGTH`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_B147qKb_0ks",
        "colab": {}
      },
      "source": [
        "MAX_SAMPLES = 100000\n",
        "def preprocess_sentence(sentence):\n",
        "  sentence = sentence.lower().strip()\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "  sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
        "  sentence = sentence.strip()\n",
        "  return sentence\n",
        "\n",
        "\n",
        "def load_conversations():\n",
        "  # dictionary of line id to text\n",
        "  id2line = {}\n",
        "  with open(ptml, errors='ignore') as file:\n",
        "    lines = file.readlines()\n",
        "  for line in lines:\n",
        "    parts = line.replace('\\n', '').split(' +++$+++ ')\n",
        "    id2line[parts[0]] = parts[4]\n",
        "\n",
        "  inputs, outputs = [], []\n",
        "  with open(ptmc, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "  for line in lines:\n",
        "    parts = line.replace('\\n', '').split(' +++$+++ ')\n",
        "    # get conversation in a list of line ID\n",
        "    conversation = [line[1:-1] for line in parts[3][1:-1].split(', ')]\n",
        "    for j in range(len(conversation) - 1):\n",
        "      inputs.append(preprocess_sentence(id2line[conversation[j]]))\n",
        "      outputs.append(preprocess_sentence(id2line[conversation[j + 1]]))\n",
        "      if len(inputs) >= MAX_SAMPLES:\n",
        "        return inputs, outputs\n",
        "  return inputs, outputs\n",
        "\n",
        "\n",
        "questions, answers = load_conversations()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mfOOK5f7Wm6c",
        "outputId": "8e6096fa-db92-4d52-8000-9d92bb4c21d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print('Sample question: {}'.format(questions[21]))\n",
        "print('Sample answer: {}'.format(answers[21]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample question: she s not a . . .\n",
            "Sample answer: lesbian ? no . i found a picture of jared leto in one of her drawers , so i m pretty sure she s not harboring same sex tendencies .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s6XX2udMTCQt",
        "colab": {}
      },
      "source": [
        "tokenizer = tflowdatasets.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "    questions + answers, target_vocab_size=2**14)\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h5h8pvRUTFt5",
        "outputId": "758a091a-e8f0-4504-f406-8af335a4d285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Tokenized sample question: {}'.format(tokenizer.encode(questions[21])))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenized sample question: [56, 9, 36, 16188, 44]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pohHm8IRWlIH",
        "outputId": "2a49d711-df70-41ee-b756-368b5d56b08b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print('Vocab size: {}'.format(VOCAB_SIZE))\n",
        "print('Number of samples: {}'.format(len(questions)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size: 16349\n",
            "Number of samples: 89168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S50jT4upWh5c"
      },
      "source": [
        "### Create `tf.data.Dataset`\n",
        "\n",
        "We are going to use the [tf.data.Dataset API](https://www.tensorflow.org/api_docs/python/tf/data) to contruct our input pipline in order to utilize features like caching and prefetching to speed up the training process.\n",
        "\n",
        "The transformer is an auto-regressive model: it makes predictions one part at a time, and uses its output so far to decide what to do next.\n",
        "\n",
        "During training this example uses teacher-forcing. Teacher forcing is passing the true output to the next time step regardless of what the model predicts at the current time step.\n",
        "\n",
        "As the transformer predicts each word, self-attention allows it to look at the previous words in the input sequence to better predict the next word.\n",
        "\n",
        "To prevent the model from peaking at the expected output the model uses a look-ahead mask.\n",
        "\n",
        "Target is divided into `decoder_inputs` which padded as an input to the decoder and `cropped_targets` for calculating our loss and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pttC3XxgAXWQ",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': questions,\n",
        "        'dec_inputs': answers[:, :-1]\n",
        "    },\n",
        "    {\n",
        "        'outputs': answers[:, 1:]\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mU8yNWpwPlS7",
        "outputId": "8e53a160-fbaf-43f5-9898-ac09d7df8ad3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(dataset)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PrefetchDataset shapes: ({inputs: (None, 40), dec_inputs: (None, 39)}, {outputs: (None, 39)}), types: ({inputs: tf.int32, dec_inputs: tf.int32}, {outputs: tf.int32})>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s9eeMPjGXmI1"
      },
      "source": [
        "## Attention\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uctkwvPZVSzu"
      },
      "source": [
        "### Scaled dot product Attention\n",
        "\n",
        "The scaled dot-product attention function used by the transformer takes three inputs: Q (query), K (key), V (value). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ENfqAFna_50H",
        "colab": {}
      },
      "source": [
        "def scaled_dot_pa(query, key, value, mask):\n",
        "  \"\"\"Calculate the attention weights. \"\"\"\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # add the mask to zero out padding tokens\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k)\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "\n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XwmOB9HvVbyh"
      },
      "source": [
        "### Multi-head attention\n",
        "\n",
        "Multi-head attention contains four segments:\n",
        "1. Linear layers and split into heads.\n",
        "2. Scaled dot-product attention.\n",
        "3. Concatenation of heads.\n",
        "4. Final linear layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L9eYssGIAG4h",
        "colab": {}
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # linear layers\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # split heads\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    # scaled dot-product attention\n",
        "    scaled_attention = scaled_dot_pa(query, key, value, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # concatenation of heads\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    # final linear layer\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eDUX7Oa8Xudj"
      },
      "source": [
        "## Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x5QlgXsxYirg"
      },
      "source": [
        "### Masking\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0CX5H8A-Wybj"
      },
      "source": [
        "`create_padding_mask` and `create_look_ahead` are helper functions to creating masks to mask out padded tokens, we are going to use these helper functions as `tf.keras.layers.Lambda` layers.\n",
        "\n",
        "Mask all the pad tokens (value `0`) in the batch to ensure the model does not treat padding as input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "imCQ0jrvWhC7",
        "colab": {}
      },
      "source": [
        "def cpm(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IrwtsqrfWd-3",
        "outputId": "29490d6a-6c4c-46a6-8ac3-faf36dd45ea2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "print(cpm(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 0. 1. 0. 1.]]]\n",
            "\n",
            "\n",
            " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qJAicy1zW1QT"
      },
      "source": [
        "Look-ahead mask to mask the future tokens in a sequence.\n",
        "We also mask out pad tokens.\n",
        "\n",
        "i.e. To predict the third word, only the first and second word will be used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HSVdD2zKWaXx",
        "colab": {}
      },
      "source": [
        "def clam(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = cpm(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xhwz9xzxWcod",
        "outputId": "4582d590-3ad1-4360-ccc1-c3e311d1333e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "print(clam(tf.constant([[1, 2, 0, 4, 5]])))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 1. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1.]\n",
            "   [0. 0. 1. 0. 1.]\n",
            "   [0. 0. 1. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TpR7kz4jFkPJ"
      },
      "source": [
        "### Positional encoding\n",
        "\n",
        "Since this model doesn't contain any recurrence or convolution, positional encoding is added to give the model some information about the relative position of the words in the sentence. \n",
        "\n",
        "The positional encoding vector is added to the embedding vector. Embeddings represent a token in a d-dimensional space where tokens with similar meaning will be closer to each other. But the embeddings do not encode the relative position of words in a sentence. So after adding the positional encoding, words will be closer to each other based on the *similarity of their meaning and their position in the sentence*, in the d-dimensional space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-9Oibz2es-qW",
        "colab": {}
      },
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HVazCemoW2Ye"
      },
      "source": [
        "### Encoder Layer\n",
        "SUBPARTS :\n",
        "* Multi-head attention (with padding mask) \n",
        "* 2 dense layers followed by dropout\n",
        "The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5guJOLJmfcuX",
        "colab": {}
      },
      "source": [
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9r8lWGClfi_1"
      },
      "source": [
        "### Encoder\n",
        "\n",
        "The Encoder consists of:\n",
        "1.   Input Embedding\n",
        "2.   Positional Encoding\n",
        "3.   `num_layers` encoder layers\n",
        "\n",
        "The input is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the encoder layers. The output of the encoder is the input to the decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LRfugon5Wy-Y",
        "colab": {}
      },
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "af66azvgW9P-"
      },
      "source": [
        "### Decoder Layer\n",
        "\n",
        "Each decoder layer consists of sublayers:\n",
        "\n",
        "1.   Masked multi-head attention (with look ahead mask and padding mask)\n",
        "2.   Multi-head attention (with padding mask). `value` and `key` receive the *encoder output* as inputs. `query` receives the *output from the masked multi-head attention sublayer.*\n",
        "3.   2 dense layers followed by dropout\n",
        "\n",
        "Each of these sublayers has a residual connection around it followed by a layer normalization. The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis.\n",
        "\n",
        "As `query` receives the output from decoder's first attention block, and `key` receives the encoder output, the attention weights represent the importance given to the decoder's input based on the encoder's output. In other words, the decoder predicts the next word by looking at the encoder output and self-attending to its own output. See the demonstration above in the scaled dot product attention section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6mLvvNMWgDnf",
        "colab": {}
      },
      "source": [
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NPSKnjS-gE_q"
      },
      "source": [
        "### Decoder\n",
        "\n",
        "The Decoder consists of:\n",
        "1.   Output Embedding\n",
        "2.   Positional Encoding\n",
        "3.   N decoder layers\n",
        "\n",
        "The target is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the decoder layers. The output of the decoder is the input to the final linear layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dYRx7YzCW4bu",
        "colab": {}
      },
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "  \n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yl0o97RJXAqw"
      },
      "source": [
        "### Transformer\n",
        "\n",
        "Transformer consists of the encoder, decoder and a final linear layer. The output of the decoder is the input to the linear layer and its output is returned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TW-v7Fz6XAfC",
        "colab": {}
      },
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9HD7GK-nh_KT"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PDDxNpA-5Q5t"
      },
      "source": [
        "### Initialize model\n",
        "\n",
        "To keep this example small and relatively fast, the values for *num_layers, d_model, and units* have been reduced. See the [paper](https://arxiv.org/abs/1706.03762) for all the other versions of the transformer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xE3unrOT5M5z",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "# Hyper-parameters\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 8\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0_GCb0LaV1tI"
      },
      "source": [
        "### Loss function\n",
        "\n",
        "Since the target sequences are padded, it is important to apply a padding mask when calculating the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UInVM9iGAMv1",
        "colab": {}
      },
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  \n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XvFM9ajSVybP"
      },
      "source": [
        "### Custom learning rate\n",
        "\n",
        "Use the Adam optimizer with a custom learning rate scheduler according to the formula in the [paper](https://arxiv.org/abs/1706.03762).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WW3SeLDhAMJd",
        "colab": {}
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "67BoG_UeaHHw",
        "outputId": "d43f5316-532a-49d8-d049-c65b43100e75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "sample_learning_rate = CustomSchedule(d_model=128)\n",
        "\n",
        "plot.plot(sample_learning_rate(tf.range(20000, dtype=tf.float32)))\n",
        "plot.ylabel(\"Learning Rate\")\n",
        "plot.xlabel(\"Train Step\")\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEGCAYAAACtqQjWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8wldz87d0xl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "abbc06bf-d639-4547-9cb4-55bc93764272"
      },
      "source": [
        "sample_learning_rate = CustomSchedule(d_model=128)\n",
        "\n",
        "plot.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
        "plot.ylabel(\"Learning Rate\")\n",
        "plot.xlabel(\"Train Step\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEGCAYAAABYV4NmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSCz+P3sOC9z2uaSSAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cCqve3kwWCxd"
      },
      "source": [
        "### Compile Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1QqojIa5WEQq",
        "colab": {}
      },
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vDMd69urLNuc"
      },
      "source": [
        "### Fit model\n",
        "\n",
        "Train our transformer by simply calling `model.fit()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d7iahRzlLNG2",
        "outputId": "be5f59fd-334f-4225-a88e-aad48cd77aa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "EPOCHS = 100\n",
        "\n",
        "model.fit(dataset, epochs=EPOCHS)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 1394 steps\n",
            "Epoch 1/100\n",
            "1394/1394 [==============================] - 207s 149ms/step - loss: 1.8664 - accuracy: 0.0579\n",
            "Epoch 2/100\n",
            "1103/1394 [======================>.......] - ETA: 41s - loss: 1.4161 - accuracy: 0.0854"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p1DUXog6WqV-"
      },
      "source": [
        "## Evaluation & Prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_NjsS3zuAbRn",
        "colab": {}
      },
      "source": [
        "def evaluation(sentence):\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  sentence = tf.expand_dims(\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "  output = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  for i in range(MAX_LENGTH):\n",
        "    predictions = model(inputs=[sentence, output], training=False)\n",
        "    predictions = predictions[:, -1:, :]\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "      break\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0)\n",
        "\n",
        "\n",
        "def predict(sentence):\n",
        "  prediction = evaluation(sentence)\n",
        "\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "  print('Input: {}'.format(sentence))\n",
        "  print('Output: {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9J3Jdtk2P-RT"
      },
      "source": [
        "MODEL TESTING!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6IeMSGEgRTvC",
        "outputId": "7482796f-aec8-4031-d7b2-f2aa5502aace",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "output = predict('are you my buddy?')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: are you my buddy?\n",
            "Output: we re not supposed to get whackup at the table .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ivVgU6ydRV8R",
        "outputId": "121ae5c7-7447-4d06-e2dd-563c8eae76ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "output = predict(\"It's a trap\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: It's a trap\n",
            "Output: i don t think it s a damn good idea .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s5zG7i8KAtRU",
        "outputId": "9e348efc-73a7-48d7-d884-a0dfef2933de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# feed the model with its previous output\n",
        "sentence = 'are arctic monkeys good?'\n",
        "for _ in range(5):\n",
        "  sentence = predict(sentence)\n",
        "  print('')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: are arctic monkeys good?\n",
            "Output: yeah . i m just wondering if you re a liar .\n",
            "\n",
            "Input: yeah . i m just wondering if you re a liar .\n",
            "Output: you re not going to stop me !\n",
            "\n",
            "Input: you re not going to stop me !\n",
            "Output: i m sorry , i m sorry .\n",
            "\n",
            "Input: i m sorry , i m sorry .\n",
            "Output: i m sorry , but it s not that good for you .\n",
            "\n",
            "Input: i m sorry , but it s not that good for you .\n",
            "Output: i m sorry .\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}